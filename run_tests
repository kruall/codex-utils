#!/usr/bin/env bash
set -uo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Always restore working directory on exit
cleanup() {
    popd >/dev/null || true
    # Clean up temporary files
    rm -f /tmp/test_output_$$ /tmp/test_stderr_$$
}

pushd "$(dirname "$0")" >/dev/null
trap cleanup EXIT

# Activate virtual environment
print_status "Activating virtual environment..."
source .venv/bin/activate

# Track test results
FAILED_TESTS=()

# Function to run a test and track results with enhanced error detection
run_test() {
    local test_name="$1"
    local test_command="$2"
    local check_console_errors="${3:-false}"
    
    print_status "Running $test_name..."
    
    # Capture both stdout and stderr
    local temp_stdout="/tmp/test_output_$$"
    local temp_stderr="/tmp/test_stderr_$$"
    
    if eval "$test_command" > "$temp_stdout" 2> "$temp_stderr"; then
        local exit_code=0
        
        # Display the output
        cat "$temp_stdout"
        cat "$temp_stderr" >&2
        
        # Check for console errors if requested
        if [ "$check_console_errors" = "true" ]; then
            if grep -q "console.error\|SyntaxError\|Failed to initialize\|Warning:" "$temp_stderr" 2>/dev/null; then
                print_error "$test_name passed but contains console errors/warnings"
                FAILED_TESTS+=("$test_name")
                exit_code=1
            fi
        fi
        
        # Check for mypy errors in stderr
        if echo "$test_command" | grep -q "mypy" && grep -q "error:" "$temp_stderr" 2>/dev/null; then
            print_error "$test_name failed with type errors"
            FAILED_TESTS+=("$test_name")
            exit_code=1
        fi
        
        # Check for ruff errors in stderr
        if echo "$test_command" | grep -q "ruff" && grep -q "error\|warning" "$temp_stderr" 2>/dev/null; then
            print_error "$test_name failed with linting errors"
            FAILED_TESTS+=("$test_name")
            exit_code=1
        fi
        
        if [ $exit_code -eq 0 ]; then
            print_success "$test_name passed"
        fi
        
        return $exit_code
    else
        # Display the output even on failure
        cat "$temp_stdout"
        cat "$temp_stderr" >&2
        print_error "$test_name failed"
        FAILED_TESTS+=("$test_name")
        return 1
    fi
}

# Run all tests, continuing even if some fail
run_test "Python unit tests" "pytest" || true

run_test "Python linting (ruff)" "ruff check ." || true

run_test "Python type checking (mypy)" "mypy ." || true

# Clean React build artifacts before running tests to avoid compiled test file issues
print_status "Cleaning React build artifacts..."
(cd react-dashboard && rm -rf .next out) || true

run_test "React tests" "(cd react-dashboard && npm test)" "true" || true

run_test "Task verification (tm verify)" "./tm verify" || true

# Summary
echo
echo "========================================="
echo "           TEST SUMMARY"
echo "========================================="

if [ ${#FAILED_TESTS[@]} -eq 0 ]; then
    print_success "All tests passed! âœ…"
    echo
    print_status "Ready for commit and deployment"
    exit 0
else
    print_error "The following tests failed:"
    for test in "${FAILED_TESTS[@]}"; do
        echo "  - $test"
    done
    echo
    print_warning "Please fix the failing tests before proceeding"
    exit 1
fi 